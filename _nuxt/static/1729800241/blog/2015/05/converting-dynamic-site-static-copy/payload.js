__NUXT_JSONP__("/blog/2015/05/converting-dynamic-site-static-copy", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK){return {data:[{},{},{},{canonical:ag,content:{title:"Converting a dynamic site into static HTML documents",locale:X,created:"2015-05-20T00:00:00.000Z",updated:"2023-02-18T00:00:00.000Z",canonical:ag,status:"publish",revising:H,caption:B,caracteresBizzares:B,gallery:B,migrateCode:H,migrateImages:B,migrateLinks:B,categories:[Y],tags:["archiving","procedure","webplatform",Y],keywords:["curl",I,"static site","convert from cms"],coverImage:{src:ah,alt:ai,text:"In March 2014, the W3C and the Web Foundation celebrated the World Wide Web 24th anniversary.\nAs a W3C Team Member, I was asked to help the systems team and host the event’s web site.\nAfter the event, I was asked to make the web site to become static HTML documents so the systems team wouldn’t have to maintain the CMS it was using.\n"},excerpt:"The following are the commands I ran on the last successful attempt to replicate the site I was working on. If you want to make a static version of your site, you might find those helpful.",preamble:{disable:H,text:e},toc:[{id:aj,depth:J,text:ak},{id:al,depth:J,text:am},{id:an,depth:J,text:ao},{id:ap,depth:J,text:aq}],body:{type:Z,children:[{type:b,tag:l,props:{},children:[{type:a,value:"Its been two times now that I've been asked to make a website that was running\non a CMS and make it static."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"This is an useful practice if you want to keep the site content for posterity\nwithout having to maintain the underlying CMS. It makes it easier to migrate\nsites since the sites that you know you won't add content to anymore becomes\nsimply a bunch of HTML files in a folder."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"My end goal was to make an EXACT copy of what the site is like when generated by\nthe CMS, BUT now stored as simple HTML files. When I say EXACT, I mean it, even\nas to keep documents at their original location from the new static files. It\nmeans that each HTML document had to keep their same value BUT that a file will\nexist and the web server will find it. For example, if a link points to "},{type:b,tag:i,props:{},children:[{type:a,value:"\u002Ffoo"}]},{type:a,value:",\nthe link in the page remain as-is, even though its now a static file at\n"},{type:b,tag:i,props:{},children:[{type:a,value:ar}]},{type:a,value:", but the web server will serve "},{type:b,tag:i,props:{},children:[{type:a,value:ar}]},{type:a,value:" anyway."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Here are a few steps I made to achieve just that. Notice that your mileage may\nvary, I've done those steps and they worked for me."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"I've done this procedure a few times with WordPress blogs along with\n"},{type:b,tag:C,props:{href:"https:\u002F\u002Fwww.w3.org\u002Fwebat25\u002F",rel:["nofollow","noopener","noreferrer"],target:"_blank"},children:[{type:b,tag:as,props:{},children:[{type:a,value:"webat25.org"}]},{type:a,value:" that is now hosted as "},{type:b,tag:as,props:{},children:[{type:a,value:"w3.org\u002Fwebat25\u002F"}]}]},{type:a,value:" website that was\nrunning on ExpressionEngine."}]},{type:a,value:f},{type:b,tag:K,props:{id:aj},children:[{type:b,tag:C,props:{href:"#steps",ariaHidden:L,tabIndex:M},children:[{type:b,tag:c,props:{className:[N,O]},children:[]}]},{type:a,value:ak}]},{type:a,value:f},{type:b,tag:K,props:{id:al},children:[{type:b,tag:C,props:{href:"#1-browse-and-get-all-pages-you-think-could-be-lost-in-scraping",ariaHidden:L,tabIndex:M},children:[{type:b,tag:c,props:{className:[N,O]},children:[]}]},{type:a,value:am}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"We want a simple file with one web page per line with its full address. This\nwill help the crawler to not forget pages."}]},{type:a,value:f},{type:b,tag:P,props:{},children:[{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Use a web browser developer tool Network inspector, keep it open with\n\"preserve log\"."}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Once you browsed the site a bit, from the network inspector tool, list all\ndocuments and then export using the \"Save as HAR\" feature."}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Extract urls from har file using "},{type:b,tag:i,props:{},children:[{type:a,value:"underscore-cli"}]}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"npm install underscore-cli cat site.har | underscore select '.entries .request\n.url' \u003E workfile.txt"}]},{type:a,value:f},{type:b,tag:P,props:{},children:[{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Remove first and last lines (its a JSON array and we want one document per\nline)"}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Remove the trailing remove hostname from each line (i.e. start by \u002Fpath), in\nvim you can do "},{type:b,tag:i,props:{},children:[{type:a,value:"%s\u002Fhttp:\\\u002F\\\u002Fwww\\.example.org\u002F\u002Fg"}]}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Remove "},{type:b,tag:i,props:{},children:[{type:a,value:q}]},{type:a,value:" and "},{type:b,tag:i,props:{},children:[{type:a,value:"\","}]},{type:a,value:" from each lines, in vim you can do "},{type:b,tag:i,props:{},children:[{type:a,value:"%s\u002F\",$\u002F\u002Fg"}]}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"At the last line, make sure the "},{type:b,tag:i,props:{},children:[{type:a,value:q}]},{type:a,value:" is removed too because the last regex\nmissed it"}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Remove duplicate lines, in vim you can do "},{type:b,tag:i,props:{},children:[{type:a,value:":sort u"}]}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:"Save this file as "},{type:b,tag:i,props:{},children:[{type:a,value:"list.txt"}]},{type:a,value:" for the next step."}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:K,props:{id:an},children:[{type:b,tag:C,props:{href:"#2-lets-scrape-everything",ariaHidden:L,tabIndex:M},children:[{type:b,tag:c,props:{className:[N,O]},children:[]}]},{type:a,value:ao}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"We'll do two scrapes. First one is to get all assets it can get, then we'll go\nagain with different options."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"The following are the commands I ran on the last successful attempt to replicate\nthe site I was working on. This is not a statement that this method is the most\nefficient technique. Please feel free to improve the document as you see fit."}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"First a quick TL;DR of "},{type:b,tag:i,props:{},children:[{type:a,value:I}]},{type:a,value:" options"}]},{type:a,value:f},{type:b,tag:P,props:{},children:[{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:"-m"}]},{type:a,value:Q},{type:b,tag:i,props:{},children:[{type:a,value:_}]}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:$}]},{type:a,value:Q},{type:b,tag:i,props:{},children:[{type:a,value:"--convert-links"}]}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:at}]},{type:a,value:Q},{type:b,tag:i,props:{},children:[{type:a,value:"--backup-converted"}]},{type:a,value:" which creates .orig files"}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:"-p"}]},{type:a,value:Q},{type:b,tag:i,props:{},children:[{type:a,value:"--page-requisites"}]},{type:a,value:" makes a page to get ALL requirements"}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:au}]},{type:a,value:" ensures we dont download the same file twice and end up with duplicates\n(e.g. file.html AND file.1.html)"}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:b,tag:i,props:{},children:[{type:a,value:"--cut-dirs"}]},{type:a,value:" would prevent creating directories and mix things around, do not\nuse."}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Notice that we're sending headers as if we were a web browser. Its up to you."}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:aa}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,D,g]},children:[{type:a,value:"UA"}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'Mozilla\u002F5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F40.0.2214.94 Safari\u002F537.36'"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:aa}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,D,g]},children:[{type:a,value:"ACCEPTL"}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'Accept-Language: fr-FR,fr;q=0.8,fr-CA;q=0.6,en-US;q=0.4,en;q=0.2'"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:aa}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,D,g]},children:[{type:a,value:"ACCEPTT"}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'Accept: text\u002Fhtml,application\u002Fxhtml+xml,application\u002Fxml;q=0.9,image\u002Fwebp,*\u002F*;q=0.8'"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:I}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ab}]},{type:a,value:av},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:au}]},{type:a,value:" --random-wait "},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:_}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:E}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,D,g]},children:[{type:a,value:aw}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:a,value:ax},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:"\n     --no-cache "},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:$}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ay}]},{type:a,value:" --page-requisites "},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:az},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:a,value:aA}]},{type:a,value:q}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ac}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:a,value:aB}]},{type:a,value:q}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:aC}]}]}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Then, another pass"}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:I}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ab}]},{type:a,value:av},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:_}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:E}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,D,g]},children:[{type:a,value:aw}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:a,value:ax},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:$}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:at}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ay}]},{type:a,value:" --no-cache --no-parent "},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:az},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:a,value:aA}]},{type:a,value:q}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ac}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:a,value:"$ACCEPTL"}]},{type:a,value:q}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:u},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ac}]},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:a,value:aB}]},{type:a,value:q}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:a,value:aC}]}]}]},{type:a,value:f},{type:b,tag:K,props:{id:ap},children:[{type:b,tag:C,props:{href:"#3-do-some-cleanup-on-the-fetched-files",ariaHidden:L,tabIndex:M},children:[{type:b,tag:c,props:{className:[N,O]},children:[]}]},{type:a,value:aq}]},{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Here are a few commands I ran to clean the files a bit"}]},{type:a,value:f},{type:b,tag:P,props:{},children:[{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Remove empty lines in every .orig files. They're the ones we'll use in the end\nafter all"}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:F}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:G}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:R}]},{type:a,value:S},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:"-regextype"}]},{type:a,value:" posix-egrep "},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:"-regex"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'.*\\.orig$'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:aD}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:T}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ab}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'s\u002F\\r\u002F\u002F'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aE}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aF}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aG}]},{type:a,value:f}]}]}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Rename the .orig file into html"}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:F}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:G}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:U}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'*orig'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:T}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:E}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"\"p;s\u002Forig\u002Fhtml\u002F\""}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:ad}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ae}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:af}]},{type:a,value:"\n\n"},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:F}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:G}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:R}]},{type:a,value:S},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:U}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'*\\.html\\.html'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:T}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:E}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"\"p;s\u002F\\.html\u002F\u002F\""}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:ad}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ae}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:af}]},{type:a,value:f}]}]}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Many folders might have only an index.html file in it. Let's just make them a\nfile without directory"}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:F}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:G}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:R}]},{type:a,value:S},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:U}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'index.html'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:T}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:E}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"\"p;s\u002F\\\u002Findex\\.html\u002F.html\u002F\""}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,o]},children:[{type:a,value:A}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:ad}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:ae}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:af}]},{type:a,value:f}]}]}]},{type:a,value:f}]},{type:a,value:f},{type:b,tag:k,props:{},children:[{type:a,value:f},{type:b,tag:l,props:{},children:[{type:a,value:"Remove files that has a "},{type:b,tag:i,props:{},children:[{type:a,value:".1"}]},{type:a,value:" (or any number in them), they are most likely\nduplicates anyway"}]},{type:a,value:f},{type:b,tag:v,props:{className:[w]},children:[{type:b,tag:x,props:{className:[y,z]},children:[{type:b,tag:i,props:{},children:[{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:F}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,s,t]},children:[{type:a,value:G}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:R}]},{type:a,value:S},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:U}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,n]},children:[{type:a,value:"'*\\.1\\.*'"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:aD}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:"rm"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,h,g]},children:[{type:a,value:"-rf"}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aE}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aF}]},{type:a,value:e},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:p}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aG}]},{type:a,value:f}]}]}]},{type:a,value:f}]},{type:a,value:f}]}]},text:"---\ntitle: Converting a dynamic site into static HTML documents\nlocale: en-CA\ncreated: 2015-05-20\nupdated: 2023-02-18\ncanonical: https:\u002F\u002Frenoirboulanger.com\u002Fblog\u002F2015\u002F05\u002Fconverting-dynamic-site-static-copy\u002F\nstatus: publish\nrevising: true\ncaption: false\ncaracteresBizzares: false\ngallery: false\nmigrateCode: true\nmigrateImages: false\nmigrateLinks: false\ncategories:\n  - techniques\ntags:\n  - archiving\n  - procedure\n  - webplatform\n  - techniques\nkeywords:\n  - curl\n  - wget\n  - static site\n  - convert from cms\ncoverImage:\n  src: ~\u002Fassets\u002Fcontent\u002Fblog\u002F2015\u002F05\u002Fwebat25-org-screen-capture.png\n  alt: Web 25th anniversary web site screenshot\n  text: |\n    In March 2014, the W3C and the Web Foundation celebrated the World Wide Web 24th anniversary.\n    As a W3C Team Member, I was asked to help the systems team and host the event’s web site.\n    After the event, I was asked to make the web site to become static HTML documents so the systems team wouldn’t have to maintain the CMS it was using.\nexcerpt: \u003E-\n  The following are the commands I ran on the last successful attempt to\n  replicate the site I was working on. If you want to make a static version of\n  your site, you might find those helpful.\npreamble:\n  disable: true\n  text: ' '\n---\n\nIts been two times now that I've been asked to make a website that was running\non a CMS and make it static.\n\nThis is an useful practice if you want to keep the site content for posterity\nwithout having to maintain the underlying CMS. It makes it easier to migrate\nsites since the sites that you know you won't add content to anymore becomes\nsimply a bunch of HTML files in a folder.\n\nMy end goal was to make an EXACT copy of what the site is like when generated by\nthe CMS, BUT now stored as simple HTML files. When I say EXACT, I mean it, even\nas to keep documents at their original location from the new static files. It\nmeans that each HTML document had to keep their same value BUT that a file will\nexist and the web server will find it. For example, if a link points to `\u002Ffoo`,\nthe link in the page remain as-is, even though its now a static file at\n`\u002Ffoo.html`, but the web server will serve `\u002Ffoo.html` anyway.\n\nHere are a few steps I made to achieve just that. Notice that your mileage may\nvary, I've done those steps and they worked for me.\n\nI've done this procedure a few times with WordPress blogs along with\n[**webat25.org** that is now hosted as **w3.org\u002Fwebat25\u002F**][0] website that was\nrunning on ExpressionEngine.\n\n## Steps\n\n## 1\\. Browse and get all pages you think could be lost in scraping\n\nWe want a simple file with one web page per line with its full address. This\nwill help the crawler to not forget pages.\n\n- Use a web browser developer tool Network inspector, keep it open with\n  \"preserve log\".\n- Once you browsed the site a bit, from the network inspector tool, list all\n  documents and then export using the \"Save as HAR\" feature.\n- Extract urls from har file using `underscore-cli`\n\nnpm install underscore-cli cat site.har | underscore select '.entries .request\n.url' \\\u003E workfile.txt\n\n- Remove first and last lines (its a JSON array and we want one document per\n  line)\n- Remove the trailing remove hostname from each line (i.e. start by \u002Fpath), in\n  vim you can do `%s\u002Fhttp:\\\u002F\\\u002Fwww\\.example.org\u002F\u002Fg`\n- Remove `\"` and `\",` from each lines, in vim you can do `%s\u002F\",$\u002F\u002Fg`\n- At the last line, make sure the `\"` is removed too because the last regex\n  missed it\n- Remove duplicate lines, in vim you can do `:sort u`\n- Save this file as `list.txt` for the next step.\n\n## 2\\. Let's scrape everything\n\nWe'll do two scrapes. First one is to get all assets it can get, then we'll go\nagain with different options.\n\nThe following are the commands I ran on the last successful attempt to replicate\nthe site I was working on. This is not a statement that this method is the most\nefficient technique. Please feel free to improve the document as you see fit.\n\nFirst a quick TL;DR of `wget` options\n\n- `-m` is the same as `--mirror`\n- `-k` is the same as `--convert-links`\n- `-K` is the same as `--backup-converted` which creates .orig files\n- `-p` is the same as `--page-requisites` makes a page to get ALL requirements\n- `-nc` ensures we dont download the same file twice and end up with duplicates\n  (e.g. file.html AND file.1.html)\n- `--cut-dirs` would prevent creating directories and mix things around, do not\n  use.\n\nNotice that we're sending headers as if we were a web browser. Its up to you.\n\n```bash\nexport UA='Mozilla\u002F5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F40.0.2214.94 Safari\u002F537.36'\nexport ACCEPTL='Accept-Language: fr-FR,fr;q=0.8,fr-CA;q=0.6,en-US;q=0.4,en;q=0.2'\nexport ACCEPTT='Accept: text\u002Fhtml,application\u002Fxhtml+xml,application\u002Fxml;q=0.9,image\u002Fwebp,*\u002F*;q=0.8'\nwget -i list.txt -nc --random-wait \\\n     --mirror \\\n     -e robots=off \\\n     --no-cache \\\n     -k -E --page-requisites \\\n     --user-agent=\"$UA\" \\\n     --header=\"$ACCEPTT\" \\\n     http:\u002F\u002Fwww.example.org\u002F\n```\n\nThen, another pass\n\n```bash\nwget -i list.txt --mirror \\\n     -e robots=off \\\n     -k -K -E --no-cache --no-parent \\\n     --user-agent=\"$UA\" \\\n     --header=\"$ACCEPTL\" \\\n     --header=\"$ACCEPTT\" \\\n     http:\u002F\u002Fwww.example.org\u002F\n```\n\n## 3\\. Do some cleanup on the fetched files\n\nHere are a few commands I ran to clean the files a bit\n\n- Remove empty lines in every .orig files. They're the ones we'll use in the end\n  after all\n\n  ```bash\n  find . -type f -regextype posix-egrep -regex '.*\\.orig$' -exec sed -i 's\u002F\\r\u002F\u002F' {} \\;\n  ```\n\n- Rename the .orig file into html\n\n  ```bash\n  find . -name '*orig' | sed -e \"p;s\u002Forig\u002Fhtml\u002F\" | xargs -n2 mv\n\n  find . -type f -name '*\\.html\\.html' | sed -e \"p;s\u002F\\.html\u002F\u002F\" | xargs -n2 mv\n  ```\n\n- Many folders might have only an index.html file in it. Let's just make them a\n  file without directory\n\n  ```bash\n  find . -type f -name 'index.html' | sed -e \"p;s\u002F\\\u002Findex\\.html\u002F.html\u002F\" | xargs -n2 mv\n  ```\n\n- Remove files that has a `.1` (or any number in them), they are most likely\n  duplicates anyway\n\n  ```bash\n  find . -type f -name '*\\.1\\.*' -exec rm -rf {} \\;\n  ```\n\n[0]: https:\u002F\u002Fwww.w3.org\u002Fwebat25\u002F\n",dir:"\u002Fblog\u002F2015\u002F05",path:"\u002Fblog\u002F2015\u002F05\u002Fconverting-dynamic-site-static-copy",extension:".md",slug:aH,createdAt:aI,updatedAt:aI,category:Y},coverImage:{toc:[],body:{type:Z,children:[{type:b,tag:l,props:{},children:[{type:a,value:"In March 2014, the "},{type:b,tag:V,props:{lang:W,title:aJ},children:[{type:a,value:aK}]},{type:a,value:" and the Web Foundation celebrated the World Wide Web 24th anniversary.\nAs a "},{type:b,tag:V,props:{lang:W,title:aJ},children:[{type:a,value:aK}]},{type:a,value:" Team Member, I was asked to help the systems team and host the event’s web site.\nAfter the event, I was asked to make the web site to become static "},{type:b,tag:V,props:{lang:W,title:"Hyper Text Markup Language"},children:[{type:a,value:"HTML"}]},{type:a,value:" documents so the systems team wouldn’t have to maintain the "},{type:b,tag:V,props:{lang:W,title:"Content Management System"},children:[{type:a,value:"CMS"}]},{type:a,value:" it was using."}]}]},text:"In March 2014, the \u003Cabbr lang=\"en\" title=\"World Wide Web Consortium, an international community where Member organizations, a full-time staff, and the public work together to develop Web standards.\"\u003EW3C\u003C\u002Fabbr\u003E and the Web Foundation celebrated the World Wide Web 24th anniversary.\nAs a \u003Cabbr lang=\"en\" title=\"World Wide Web Consortium, an international community where Member organizations, a full-time staff, and the public work together to develop Web standards.\"\u003EW3C\u003C\u002Fabbr\u003E Team Member, I was asked to help the systems team and host the event’s web site.\nAfter the event, I was asked to make the web site to become static \u003Cabbr lang=\"en\" title=\"Hyper Text Markup Language\"\u003EHTML\u003C\u002Fabbr\u003E documents so the systems team wouldn’t have to maintain the \u003Cabbr lang=\"en\" title=\"Content Management System\"\u003ECMS\u003C\u002Fabbr\u003E it was using.\n",src:ah,alt:ai},month:"05",next:{title:"Add OpenStack instance meta-data info in your salt grains",locale:X,path:"\u002Fblog\u002F2015\u002F05\u002Fadd-openstack-instance-meta-data-info-salt-grains",slug:"add-openstack-instance-meta-data-info-salt-grains"},preamble:{toc:[],body:{type:Z,children:[]},text:e,disable:H},prettyfiedTemporalDate:{prettified:"Wednesday, May 20, 2015",temporalDate:"2015-05-20"},prev:{title:"Run a NodeJS process through forever from within a Docker container",locale:X,path:"\u002Fblog\u002F2015\u002F05\u002Frun-nodejs-process-forever-within-docker-container",slug:"run-nodejs-process-forever-within-docker-container"},slug:aH,year:"2015"}],fetch:[],mutations:void 0}}("text","element","span","token"," ","\n","variable","parameter","code","punctuation","li","p","function","string","operator","\\","\"","=","builtin","class-name","\n     ","div","nuxt-content-highlight","pre","language-bash","line-numbers","|",false,"a","assign-left","-e","find",".",true,"wget",2,"h2","true",-1,"icon","icon-link","ul"," is the same as ","-type"," f ","sed","-name","abbr","en","en-CA","techniques","root","--mirror","-k","export","-i","--header","xargs","-n2","mv","https:\u002F\u002Frenoirboulanger.com\u002Fblog\u002F2015\u002F05\u002Fconverting-dynamic-site-static-copy\u002F","~\u002Fassets\u002Fcontent\u002Fblog\u002F2015\u002F05\u002Fwebat25-org-screen-capture.png","Web 25th anniversary web site screenshot","steps","Steps","1-browse-and-get-all-pages-you-think-could-be-lost-in-scraping","1. Browse and get all pages you think could be lost in scraping","2-lets-scrape-everything","2. Let's scrape everything","3-do-some-cleanup-on-the-fetched-files","3. Do some cleanup on the fetched files","\u002Ffoo.html","strong","-K","-nc"," list.txt ","robots","off ","-E","\n     --user-agent","$UA","$ACCEPTT","\n     http:\u002F\u002Fwww.example.org\u002F\n","-exec","{","}",";","converting-dynamic-site-static-copy","2024-10-24T19:50:04.932Z","World Wide Web Consortium, an international community where Member organizations, a full-time staff, and the public work together to develop Web standards.","W3C")));